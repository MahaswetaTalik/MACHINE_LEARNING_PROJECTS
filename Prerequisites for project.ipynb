{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2e47142-af16-4fa1-a595-c6f01090c3b7",
   "metadata": {},
   "source": [
    "# Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b31d88-4f29-4ddd-9cea-5a9ea324a03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing values for each column\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee90e58-c70c-4635-936b-d8dd9f2fe31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using imputation(mean,median,mode) instead of dropping rows or columns\n",
    "dataset['column_name'].fillna(dataset['column_name'].median(),inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2237c7-f3d8-4126-8ce3-674a0c5f121c",
   "metadata": {},
   "source": [
    "# Data Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18229430-85f2-4351-b6b2-0d66e802c190",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b8db1b-2096-4320-b354-ae69d0143398",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df \n",
    "Y = dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cadd94e-a3e2-4fd7-9cd4-fa35853e7944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting tarining and test data\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=3) # test_size should be between 0.1-0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b246959f-6dc2-41c4-994b-d2fa53d4cb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.train_shape\n",
    "Y.test_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d20e43d-9a4d-45d2-9b63-4c5d5ecaa7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fix(X_train)\n",
    "\n",
    "X_train_standardized = scaler.transform(X_train) # for train data\n",
    "X_train_standardized.std()\n",
    "\n",
    "X_train_standardized = scaler.transform(X_train) # for test data\n",
    "X_train_standardized.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2cf53d-edf7-4ce1-8920-7259b2be8da4",
   "metadata": {},
   "source": [
    "# Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1433c46-95b2-43d6-9abe-c08f74879eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f9f019-eab0-453d-b6ee-9e84262d06cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding count of different labels\n",
    "data['column_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcdceb1-893b-48f3-9224-66eeea215aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(data.'column_name')\n",
    "\n",
    "# appending labels to dataframe\n",
    "data['target'] = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c594bff2-d2b6-4dfb-ad7d-4b6101d579b8",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4bd2e6-c442-4dde-bcf0-1b7c417f347b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_ectraction.text import TfidVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faa8681-b92e-4cfe-8538-d6bbe11efff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating data and label\n",
    "X = dataset['column_name'].values\n",
    "Y = dataset['column_name'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf9cf10-2ed7-4430-957a-44e4d6101154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert textual data into feature vector\n",
    "vectorizer = TfidVectorizer\n",
    "vectorizer.fit(X)\n",
    "X = vectorizer.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7236f642-4b6b-447b-844a-c9dc2d8a806d",
   "metadata": {},
   "source": [
    "# Text Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bed7fa-afe5-4119-a8d2-65bdd2b50511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopwords are used in text preprocessing to remove common words like \"the,\" \"is,\" and \"and\" that donâ€™t add meaning to NLP models. \n",
    "# This helps reduce noise, improve efficiency, and focus on important words for better analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c15f7d3-9b2b-48b8-b11e-d0a727812211",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install nltk spacy pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e562f2e-a818-4ba7-ad7f-a91681e65620",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060ce8a1-78f3-4218-b860-746e4be27f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3473f19a-bb10-41a2-9c0d-ee039e7a8ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This is an example sentence to demonstrate stopword removal using regex.\"\n",
    "\n",
    "# Create regex pattern for stopwords\n",
    "stopword_pattern = r'\\b(?:' + '|'.join(stop_words) + r')\\b'\n",
    "\n",
    "# Remove stopwords using re.sub\n",
    "cleaned_text = re.sub(stopword_pattern, '', text, flags=re.IGNORECASE)\n",
    "\n",
    "# Remove extra spaces\n",
    "cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
    "\n",
    "print(cleaned_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423ddc89-b6fb-44c8-bcd0-c74378310977",
   "metadata": {},
   "source": [
    "# Steps to Make Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f25465d-59d4-4cd4-b881-acc2945268af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. import libraries\n",
    "# 2. load dataset\n",
    "# 3. describe and shape\n",
    "# 4. value counts\n",
    "# 5. delete outcome or result column if have\n",
    "# 6. data standardization\n",
    "# 7. data splitting into train and test data\n",
    "# 8. train the model with the training data\n",
    "# 9. model evaluation\n",
    "# 10. make predictive system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5b0d3b-d857-4837-904e-5da29f4659e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
